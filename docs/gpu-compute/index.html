
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0">


  
<script>
  // A global function that the theme toggle can use to apply the current theme.
  window.applyThemeSetting = function(override) {
    const currentSetting = override || localStorage.getItem('user-color-scheme');
    const currentAttribute = document.documentElement.getAttribute('data-user-theme');

    if (currentSetting && currentSetting !== currentAttribute) {
      document.documentElement.setAttribute('data-user-theme', currentSetting);
    }
  };
window.applyThemeSetting();
</script>

  
  <link rel="stylesheet" href="/css/next.css?v=fffb4a3618dba">
  <link rel="stylesheet" href="/css/legacy-rollout.css?v=ba2752a293dee">
  <link rel="preload" as="font" crossorigin href="/fonts/material-icons/regular.woff2">


<link rel="preload" as="font" crossorigin href="/fonts/google-sans/regular/latin.woff2">
<link rel="preload" as="font" crossorigin href="/fonts/google-sans/bold/latin.woff2">

<meta name="theme-color" content="#fff"/>




<title>Get started with GPU Compute on the web</title>
<meta name="description" content="This post explores the experimental WebGPU API through examples and helps you get started with performing data-parallel computations using the GPU. " />

<link rel="canonical" href="https://web.dev/gpu-compute/" />

<meta itemprop="name" content="Get started with GPU Compute on the web" />
<meta itemprop="description" content="This post explores the experimental WebGPU API through examples and helps you get started with performing data-parallel computations using the GPU. " />
<meta itemprop="image" content="https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format&fit=max&w=1200&fm=auto" />
<meta property="og:locale" content="en_US" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://web.dev/gpu-compute/" />
<meta property="og:site_name" content="web.dev" />
<meta property="og:title" content="Get started with GPU Compute on the web" />
<meta property="og:description" content="This post explores the experimental WebGPU API through examples and helps you get started with performing data-parallel computations using the GPU. " />
<meta property="og:image" content="https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format&fit=max&w=1200&fm=auto" />
<meta property="og:image:alt" content="" />
<meta property="tag" content="capabilities" />
<meta property="tag" content="games" />
<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:title" content="Get started with GPU Compute on the web" />
<meta name="twitter:description" content="This post explores the experimental WebGPU API through examples and helps you get started with performing data-parallel computations using the GPU. " />
<meta name="twitter:image" content="https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format&fit=max&w=1200&fm=auto" />
<link
  rel="alternate"
  href="/feed.xml"
  type="application/atom+xml"
  data-title="web.dev feed"
/>

<link rel="manifest" href="/manifest.webmanifest" />

<link rel="shortcut icon" href="/images/favicon.ico">
<link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
<link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
<link rel="mask-icon" color="#0054ff" href="/images/safari-pinned-tab.svg">



<script>
window.ga =
  window.ga ||
  function () {
    (ga.q = ga.q || []).push(arguments);
  };
ga.l = +new Date();
ga('create', 'UA-126406676-2');
ga('set', 'transport', 'beacon');
ga('set', 'anonymizeIp', true);
ga('set', 'page', window.location.pathname);
ga('set', 'dimension5', '4');
ga('send', 'pageview');
</script>







<script>
function loadScript(url, type) {
  const s = document.createElement('script');
  s.src = url;
  if (type) {
    s.type = type;
  }
  if (type === 'module') {
    s.async = false; // Preserve load order.
    const pre = document.createElement('link');
    pre.rel = 'modulepreload';
    pre.href = url;
    document.head.append(pre);
    // We use DOMContentLoaded as the loader script is running sync, and inserting a module script here doesn't defer. This brings back normal type="module" behavior.
    window.addEventListener('DOMContentLoaded', () => {
      document.head.append(s);
    });
  } else {
    document.head.append(s);
  }
}
loadScript('/js/app.js?v=96e2c7a67dfbe', 'module');




  loadScript('/js/content.js?v=c5ff19d275352', 'module');


  loadScript('https://www.google-analytics.com/analytics.js', null);

</script>

  </head>
  <body class="unresolved">
    
    <web-snackbar-container></web-snackbar-container>

    
<a href="#main" class="skip-link button" data-type="primary">Skip to content</a>


<web-header role="banner" class="site-header">
  <div class="cluster gutter-base">
    <button class="icon-button tooltip color-core-text md:hidden-yes" data-open-drawer-button data-alignment="right">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" height="24" width="24"><path d="M0 0h24v24H0z" fill="none"/><path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/></svg>
      <span class="tooltip__content">Open menu</span>
    </button>
    <a href="/" class="site-header__brand brand">
      


  <svg role="img" aria-label="web.dev" xmlns="http://www.w3.org/2000/svg" width="119.79" height="22.32" viewBox="0 0 119.79 22.32"><path class="brand__text" d="M114.99 19.32h-2.2l-4.8-11.9h2.4l3.5 9.2 3.5-9.2h2.4Zm-16.8-7.3h6.8a3.17 3.17 0 0 0-3.4-2.9 3.42 3.42 0 0 0-3.4 2.9Zm3.6 7.7a6 6 0 0 1-6-6.3c0-3.6 2.5-6.3 5.9-6.3s5.8 2.4 5.8 6.5v.2h-9.3a3.88 3.88 0 0 0 3.8 3.9 3.56 3.56 0 0 0 3.3-2.1l2 1a6.22 6.22 0 0 1-5.5 3.1Zm-14 0c-3.1 0-5.7-2.8-5.7-6.3s2.6-6.3 5.7-6.3a5 5 0 0 1 4.1 2h.1l-.1-1.6v-5.5h2.2v17.3h-2.1v-1.6h-.1a5.12 5.12 0 0 1-4.1 2Zm.3-2c2.2 0 3.8-1.7 3.8-4.3s-1.6-4.3-3.8-4.3a4 4 0 0 0-3.8 4.3 4 4 0 0 0 3.8 4.3Zm-6.8.1a1.61 1.61 0 0 1-1.7 1.6 1.74 1.74 0 0 1-1.7-1.6 1.67 1.67 0 0 1 1.7-1.6 1.61 1.61 0 0 1 1.7 1.6Zm-10.5-.1a4 4 0 0 0 3.8-4.3 4 4 0 0 0-3.8-4.3c-2.2 0-3.8 1.8-3.8 4.3s1.6 4.3 3.8 4.3Zm.4 2a5 5 0 0 1-4.1-2h-.1v1.6h-2.1V2.02h2.2v5.5l-.1 1.6h.1a4.84 4.84 0 0 1 4.1-2c3.1 0 5.7 2.8 5.7 6.3s-2.6 6.3-5.7 6.3Zm-17.4-7.7h6.8a3.17 3.17 0 0 0-3.4-2.9 3.42 3.42 0 0 0-3.4 2.9Zm3.6 7.7a6 6 0 0 1-6-6.3c0-3.6 2.5-6.3 5.9-6.3s5.8 2.4 5.8 6.5v.2h-9.3a3.88 3.88 0 0 0 3.8 3.9 3.67 3.67 0 0 0 3.3-2.1l2 1a6.22 6.22 0 0 1-5.5 3.1Zm-6.3-12.2-3.8 11.9h-2.3l-3-9.1-2.9 9.1h-2.3l-3.9-11.9h2.3l2.6 9 2.9-9h2.3l2.9 9 2.6-9Z" fill="#5f6368" fill-rule="evenodd"/><path d="M0 19.28a3 3 0 0 1 3-3h16.27a3.045 3.045 0 0 1 0 6.09H3.04A3 3 0 0 1 0 19.28Z" fill="#6cf"/><path d="M.89.9a3 3 0 0 1 4.3 0l8.12 8.11a3.05 3.05 0 0 1 0 4.3l-8.12 8.12a3.04 3.04 0 1 1-4.3-4.3l5.6-5.61a.51.51 0 0 0 0-.72L.89 5.22A3 3 0 0 1 .89.9Z" fill="#06f" fill-rule="evenodd"/><path d="m10.39 16.22-5.2 5.2a3.04 3.04 0 1 1-4.3-4.3l.89-.9Z" fill="#c6f"/><circle cx="19.27" cy="19.27" r="3.04" fill="#06f"/></svg>


    </a>
  </div>
  <web-navigation-drawer type="standard">
    <nav class="site-header__nav" aria-label="main navigation" data-drawer-container>
      <a
        class="site-header__link"
        href="/learn/" data-category="Site-Wide Custom Events"
        data-label="Tab: Learn"
        >
          Learn
      </a>
      <a
        class="site-header__link"
        href="/measure/"
        data-category="Site-Wide Custom Events"
        data-label="Tab: Measure"
        >
        Measure
      </a>
      <a
        class="site-header__link"
        href="/blog/"
        data-category="Site-Wide Custom Events"
        data-label="Tab: Blog"
        >
        Blog
      </a>
      <a
        class="site-header__link"
        href="/tags/case-study/"
        data-category="Site-Wide Custom Events"
        data-label="Tab: Case Studies"
        >
        Case studies
      </a>
      <a
        class="site-header__link"
        href="/about/"
        data-category="Site-Wide Custom Events"
        data-label="Tab: About" >
        About
      </a>
      <button class="icon-button tooltip color-core-text md:hidden-yes" data-drawer-close-button>
        








  










  <svg class="icon " role="img" aria-label="close" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" height="24" width="24"><path d="M0 0h24v24H0z" fill="none"/><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>


        <span class="tooltip__content">Close</span>
      </button>
    </nav>
  </web-navigation-drawer>
  <div class="site-header__actions cluster">
    <div class="site-header__search">
      <web-search results-id="search-main-results" i18n="{&quot;search&quot;:{&quot;en&quot;:&quot;Search&quot;},&quot;open_search&quot;:{&quot;en&quot;:&quot;Open search&quot;},&quot;all_articles&quot;:{&quot;en&quot;:&quot;All articles&quot;},&quot;close_search&quot;:{&quot;en&quot;:&quot;Close search&quot;}}"></web-search>
      <web-search-results id="search-main-results"></web-search-results>
    </div>
  </div>
</web-header>

<main id="main">
  
    
  
  





  <img     alt=""     class="hero-image"     decoding="async"     height="480"               sizes="100vw"     src="https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format"     srcset="https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format&w=200 200w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format&w=228 228w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format&w=260 260w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format&w=296 296w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format&w=338 338w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format&w=385 385w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format&w=439 439w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format&w=500 500w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format&w=571 571w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format&w=650 650w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format&w=741 741w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format&w=845 845w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format&w=964 964w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format&w=1098 1098w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format&w=1252 1252w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format&w=1428 1428w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format&w=1600 1600w"          width="1600"   />


<div class="post wrapper" data-flush>
  
    
    
    
  
  

  <div class="sidebar region flex-align-start flex-dir-rev flex-wrap-no">
    

  <nav class="course__toc toc over-scroll hidden-yes xl:hidden-no" data-type="side" aria-label="On this page">
    <div class="course-toc__heading font-google-sans weight-medium">On this page</div>
    <web-scroll-spy>
      <div class="toc__wrapper flow-recursive">
        <ul class="toc__list"><li class="toc__listitem"><a class="toc__anchor" href="#background">Background</a></li><li class="toc__listitem"><a class="toc__anchor" href="#access-the-gpu">Access the GPU</a></li><li class="toc__listitem"><a class="toc__anchor" href="#write-buffer-memory">Write buffer memory</a></li><li class="toc__listitem"><a class="toc__anchor" href="#read-buffer-memory">Read buffer memory</a></li><li class="toc__listitem"><a class="toc__anchor" href="#shader-programming">Shader programming</a><ul class="toc__list"><li class="toc__listitem"><a class="toc__anchor" href="#gpu-buffers-creation">GPU Buffers creation</a></li><li class="toc__listitem"><a class="toc__anchor" href="#bind-group-layout-and-bind-group">Bind group layout and bind group</a></li><li class="toc__listitem"><a class="toc__anchor" href="#compute-shader-code">Compute shader code</a></li><li class="toc__listitem"><a class="toc__anchor" href="#pipeline-setup">Pipeline setup</a></li><li class="toc__listitem"><a class="toc__anchor" href="#commands-submission">Commands submission</a></li><li class="toc__listitem"><a class="toc__anchor" href="#read-result-matrix">Read result matrix</a></li></ul></li><li class="toc__listitem"><a class="toc__anchor" href="#one-last-trick">One last trick</a></li><li class="toc__listitem"><a class="toc__anchor" href="#performance-findings">Performance findings</a></li></ul>
      </div>
    </web-scroll-spy>
  </nav>


    
    <article class="prose legacy-rollout">
      <header class="flow gap-bottom-size-3">
        
          <nav class="breadcrumbs" aria-label="breadcrumbs">
            <ul class="breadcrumbs__list" role="list">
              <li>
                <a
                  class="gc-analytics-event"
                  data-category="web.dev"
                  data-label="post, home breadcrumb"
                  data-action="click"
                  href="/"
                >
                  Home
                </a>
              </li>
              
              <li>
                <a
                  class="gc-analytics-event"
                  data-category="web.dev"
                  data-label="post, path breadcrumb"
                  data-action="click"
                  href="/blog"
                >
                  All articles
                </a>
              </li>
              
            </ul>
          </nav>
        

        <h1 id="get-started-with-gpu-compute-on-the-web">Get started with GPU Compute on the web</h1>
        
          <p class="color-mid-text flow-space-base">
            <p>This post explores the experimental WebGPU API through examples and helps
you get started with performing data-parallel computations using the GPU.</p>

          </p>
        

        
          <div class="flow-space-size-1 color-mid-text text-size-0">
            <time>Aug 28, 2019</time>
             — Updated <time>Oct 18, 2021</time> 
          </div>
        

        
        

        

        
          <div class="cluster flow-space-size-2">
            
              <div class="author">
  <a class="avatar" href="/authors/beaufortfrancois/"> <img     alt="François Beaufort"     class="w-author__image"     decoding="async"     height="64"          loading="lazy"     sizes="(min-width: 64px) 64px, calc(100vw - 48px)"     src="https://web-dev.imgix.net/image/admin/mXjY3z3JmrispGtu9yn6.jpg?auto=format&fit=crop&h=64&w=64"     srcset="https://web-dev.imgix.net/image/admin/mXjY3z3JmrispGtu9yn6.jpg?fit=crop&h=64&w=64&auto=format&dpr=1&q=75 1x,     https://web-dev.imgix.net/image/admin/mXjY3z3JmrispGtu9yn6.jpg?fit=crop&h=64&w=64&auto=format&dpr=2&q=50 2x,     https://web-dev.imgix.net/image/admin/mXjY3z3JmrispGtu9yn6.jpg?fit=crop&h=64&w=64&auto=format&dpr=3&q=35 3x,     https://web-dev.imgix.net/image/admin/mXjY3z3JmrispGtu9yn6.jpg?fit=crop&h=64&w=64&auto=format&dpr=4&q=23 4x,     https://web-dev.imgix.net/image/admin/mXjY3z3JmrispGtu9yn6.jpg?fit=crop&h=64&w=64&auto=format&dpr=5&q=20 5x"          width="64"   /> </a>
  <div class="flow">
    <cite class="author__name">
      <a href="/authors/beaufortfrancois/">François Beaufort</a>
    </cite>
    <div class="author__links cluster">
               
               <a href="https://github.com/beaufortfrancois">GitHub</a>
               
               
             </div>
  </div>
</div>
            
          </div>
        
      </header>

      

      

  

  <div class="xl:hidden-yes flow-space-size-1">
    <details data-type="inner" role="navigation" aria-label="On this page">
      <summary>
        On this page
      </summary>
      <div class="toc"><ul class="toc__list"><li class="toc__listitem"><a class="toc__anchor" href="#background">Background</a></li><li class="toc__listitem"><a class="toc__anchor" href="#access-the-gpu">Access the GPU</a></li><li class="toc__listitem"><a class="toc__anchor" href="#write-buffer-memory">Write buffer memory</a></li><li class="toc__listitem"><a class="toc__anchor" href="#read-buffer-memory">Read buffer memory</a></li><li class="toc__listitem"><a class="toc__anchor" href="#shader-programming">Shader programming</a><ul class="toc__list"><li class="toc__listitem"><a class="toc__anchor" href="#gpu-buffers-creation">GPU Buffers creation</a></li><li class="toc__listitem"><a class="toc__anchor" href="#bind-group-layout-and-bind-group">Bind group layout and bind group</a></li><li class="toc__listitem"><a class="toc__anchor" href="#compute-shader-code">Compute shader code</a></li><li class="toc__listitem"><a class="toc__anchor" href="#pipeline-setup">Pipeline setup</a></li><li class="toc__listitem"><a class="toc__anchor" href="#commands-submission">Commands submission</a></li><li class="toc__listitem"><a class="toc__anchor" href="#read-result-matrix">Read result matrix</a></li></ul></li><li class="toc__listitem"><a class="toc__anchor" href="#one-last-trick">One last trick</a></li><li class="toc__listitem"><a class="toc__anchor" href="#performance-findings">Performance findings</a></li></ul></div>
    </details>
  </div>



      <h2 id="background">Background <a class="w-headline-link" href="#background">#</a></h2>
<p>As you may already know, the Graphic Processing Unit (GPU) is an electronic
subsystem within a computer that was originally specialized for processing
graphics. However, in the past 10 years, it has evolved towards a more flexible
architecture allowing developers to implement many types of algorithms, not just
render 3D graphics, while taking advantage of the unique architecture of the
GPU. These capabilities are referred to as GPU Compute, and using a GPU as a
coprocessor for general-purpose scientific computing is called general-purpose
GPU (GPGPU) programming.</p>
<p>GPU Compute has contributed significantly to the recent machine learning boom,
as convolution neural networks and other models can take advantage of the
architecture to run more efficiently on GPUs. With the current Web Platform
lacking in GPU Compute capabilities, the W3C's &quot;GPU for the Web&quot; Community Group
is designing an API to expose the modern GPU APIs that are available on most
current devices. This API is called <a href="https://gpuweb.github.io/gpuweb/" rel="noopener">WebGPU</a>.</p>
<p>WebGPU is a low-level API, like WebGL. It is very powerful and quite verbose, as
you'll see. But that's OK. What we're looking for is performance.</p>
<p>In this article, I'm going to focus on the GPU Compute part of WebGPU and, to be
honest, I'm just scratching the surface, so that you can start playing on your
own. I will be diving deeper and covering WebGPU rendering (canvas, texture,
etc.) in forthcoming articles.</p>
<aside class="aside flow bg-state-info-bg color-state-info-text">
<div class=" flow">
<p>WebGPU is available for now in Chrome Canary on desktop behind an
experimental flag. You can enable it at <code>chrome://flags/#enable-unsafe-webgpu</code>. The
API is constantly changing and currently unsafe. As GPU sandboxing isn't
implemented yet for the WebGPU API, it is possible to read GPU data for other
processes! Don't browse the web with it enabled.</p>
</div></aside>
<h2 id="access-the-gpu">Access the GPU <a class="w-headline-link" href="#access-the-gpu">#</a></h2>
<p>Accessing the GPU is easy in WebGPU. Calling <code>navigator.gpu.requestAdapter()</code>
returns a JavaScript promise that will asynchronously resolve with a GPU
adapter. Think of this adapter as the graphics card. It can either be integrated
(on the same chip as the CPU) or discrete (usually a PCIe card that is more
performant but uses more power).</p>
<p>Once you have the GPU adapter, call <code>adapter.requestDevice()</code> to get a promise
that will resolve with a GPU device you'll use to do some GPU computation.</p>
<web-copy-code><pre class="language-js"><code class="language-js"><span class="token keyword">const</span> adapter <span class="token operator">=</span> <span class="token keyword">await</span> navigator<span class="token punctuation">.</span>gpu<span class="token punctuation">.</span><span class="token function">requestAdapter</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>adapter<span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token keyword">return</span><span class="token punctuation">;</span> <span class="token punctuation">}</span><br><span class="token keyword">const</span> device <span class="token operator">=</span> <span class="token keyword">await</span> adapter<span class="token punctuation">.</span><span class="token function">requestDevice</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre>
</web-copy-code><p>Both functions take options that allow you to be specific about the kind of
adapter (power preference) and device (extensions, limits) you want. For the
sake of simplicity, we'll use the default options in this article.</p>
<h2 id="write-buffer-memory">Write buffer memory <a class="w-headline-link" href="#write-buffer-memory">#</a></h2>
<p>Let's see how to use JavaScript to write data to memory for the GPU. This
process isn't straightforward because of the sandboxing model used in modern web
browsers.</p>
<p>The example below shows you how to write four bytes to buffer memory accessible
from the GPU. It calls <code>device.createBuffer()</code> which takes the size of the
buffer and its usage. Even though the usage flag <code>GPUBufferUsage.MAP_WRITE</code> is
not required for this specific call, let's be explicit that we want to write
to this buffer. It results in a GPU buffer object mapped at creation thanks to
<code>mappedAtCreation</code> set to true. Then the associated raw binary data buffer can
be retrieved by calling the GPU buffer method <code>getMappedRange()</code>.</p>
<p>Writing bytes is familiar if you've already played with <code>ArrayBuffer</code>; use a
<code>TypedArray</code> and copy the values into it.</p>
<web-copy-code><pre class="language-js"><code class="language-js"><span class="token comment">// Get a GPU buffer in a mapped state and an arrayBuffer for writing.</span><br><span class="token keyword">const</span> gpuBuffer <span class="token operator">=</span> device<span class="token punctuation">.</span><span class="token function">createBuffer</span><span class="token punctuation">(</span><span class="token punctuation">{</span><br>  mappedAtCreation<span class="token operator">:</span> <span class="token boolean">true</span><span class="token punctuation">,</span><br>  size<span class="token operator">:</span> <span class="token number">4</span><span class="token punctuation">,</span><br>  usage<span class="token operator">:</span> GPUBufferUsage<span class="token punctuation">.</span><span class="token constant">MAP_WRITE</span><br><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><span class="token keyword">const</span> arrayBuffer <span class="token operator">=</span> gpuBuffer<span class="token punctuation">.</span><span class="token function">getMappedRange</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><br><span class="token comment">// Write bytes to buffer.</span><br><span class="token keyword">new</span> <span class="token class-name">Uint8Array</span><span class="token punctuation">(</span>arrayBuffer<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre>
</web-copy-code><p>At this point, the GPU buffer is mapped, meaning it is owned by the CPU, and
it's accessible in read/write from JavaScript. So that the GPU can access it, it
has to be unmapped which is as simple as calling <code>gpuBuffer.unmap()</code>.</p>
<p>The concept of mapped/unmapped is needed to prevent race conditions where GPU
and CPU access memory at the same time.</p>
<h2 id="read-buffer-memory">Read buffer memory <a class="w-headline-link" href="#read-buffer-memory">#</a></h2>
<p>Now let's see how to copy a GPU buffer to another GPU buffer and read it back.</p>
<p>Since we're writing in the first GPU buffer and we want to copy it to a second
GPU buffer, a new usage flag <code>GPUBufferUsage.COPY_SRC</code> is required. The second
GPU buffer is created in an unmapped state this time with
<code>device.createBuffer()</code>. Its usage flag is <code>GPUBufferUsage.COPY_DST | GPUBufferUsage.MAP_READ</code> as it will be used as the destination of the first GPU
buffer and read in JavaScript once GPU copy commands have been executed.</p>
<web-copy-code><pre class="language-js"><code class="language-js"><span class="token comment">// Get a GPU buffer in a mapped state and an arrayBuffer for writing.</span><br><span class="token keyword">const</span> gpuWriteBuffer <span class="token operator">=</span> device<span class="token punctuation">.</span><span class="token function">createBuffer</span><span class="token punctuation">(</span><span class="token punctuation">{</span><br>  mappedAtCreation<span class="token operator">:</span> <span class="token boolean">true</span><span class="token punctuation">,</span><br>  size<span class="token operator">:</span> <span class="token number">4</span><span class="token punctuation">,</span><br>  usage<span class="token operator">:</span> GPUBufferUsage<span class="token punctuation">.</span><span class="token constant">MAP_WRITE</span> <span class="token operator">|</span> GPUBufferUsage<span class="token punctuation">.</span><span class="token constant">COPY_SRC</span><br><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><span class="token keyword">const</span> arrayBuffer <span class="token operator">=</span> gpuWriteBuffer<span class="token punctuation">.</span><span class="token function">getMappedRange</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><br><span class="token comment">// Write bytes to buffer.</span><br><span class="token keyword">new</span> <span class="token class-name">Uint8Array</span><span class="token punctuation">(</span>arrayBuffer<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><br><span class="token comment">// Unmap buffer so that it can be used later for copy.</span><br>gpuWriteBuffer<span class="token punctuation">.</span><span class="token function">unmap</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><br><span class="token comment">// Get a GPU buffer for reading in an unmapped state.</span><br><span class="token keyword">const</span> gpuReadBuffer <span class="token operator">=</span> device<span class="token punctuation">.</span><span class="token function">createBuffer</span><span class="token punctuation">(</span><span class="token punctuation">{</span><br>  size<span class="token operator">:</span> <span class="token number">4</span><span class="token punctuation">,</span><br>  usage<span class="token operator">:</span> GPUBufferUsage<span class="token punctuation">.</span><span class="token constant">COPY_DST</span> <span class="token operator">|</span> GPUBufferUsage<span class="token punctuation">.</span><span class="token constant">MAP_READ</span><br><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre>
</web-copy-code><p>Because the GPU is an independent coprocessor,  all GPU commands are executed
asynchronously. This is why there is a list of GPU commands built up and sent in
batches when needed. In WebGPU, the GPU command encoder returned by
<code>device.createCommandEncoder()</code>is the JavaScript object that builds a batch of
&quot;buffered&quot; commands that will be sent to the GPU at some point. The methods on
<code>GPUBuffer</code>, on the other hand, are &quot;unbuffered&quot;, meaning they execute atomically
at the time they are called.</p>
<p>Once you have the GPU command encoder, call <code>copyEncoder.copyBufferToBuffer()</code>
as shown below to add this command to the command queue for later execution.
Finally, finish encoding commands by calling <code>copyEncoder.finish()</code> and submit
those to the GPU device command queue. The queue is responsible for handling
submissions done via <code>device.queue.submit()</code> with the GPU commands as arguments.
This will atomically execute all the commands stored in the array in order.</p>
<web-copy-code><pre class="language-js"><code class="language-js"><span class="token comment">// Encode commands for copying buffer to buffer.</span><br><span class="token keyword">const</span> copyEncoder <span class="token operator">=</span> device<span class="token punctuation">.</span><span class="token function">createCommandEncoder</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br>copyEncoder<span class="token punctuation">.</span><span class="token function">copyBufferToBuffer</span><span class="token punctuation">(</span><br>  gpuWriteBuffer <span class="token comment">/* source buffer */</span><span class="token punctuation">,</span><br>  <span class="token number">0</span> <span class="token comment">/* source offset */</span><span class="token punctuation">,</span><br>  gpuReadBuffer <span class="token comment">/* destination buffer */</span><span class="token punctuation">,</span><br>  <span class="token number">0</span> <span class="token comment">/* destination offset */</span><span class="token punctuation">,</span><br>  <span class="token number">4</span> <span class="token comment">/* size */</span><br><span class="token punctuation">)</span><span class="token punctuation">;</span><br><br><span class="token comment">// Submit copy commands.</span><br><span class="token keyword">const</span> copyCommands <span class="token operator">=</span> copyEncoder<span class="token punctuation">.</span><span class="token function">finish</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br>device<span class="token punctuation">.</span>queue<span class="token punctuation">.</span><span class="token function">submit</span><span class="token punctuation">(</span><span class="token punctuation">[</span>copyCommands<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre>
</web-copy-code><p>At this point, GPU queue commands have been sent, but not necessarily executed.
To read the second GPU buffer, call <code>gpuReadBuffer.mapAsync()</code> with
<code>GPUMapMode.READ</code>. It returns a promise that will resolve when the GPU buffer is
mapped. Then get the mapped range with <code>gpuReadBuffer.getMappedRange()</code> that
contains the same values as the first GPU buffer once all queued GPU commands
have been executed.</p>
<web-copy-code><pre class="language-js"><code class="language-js"><span class="token comment">// Read buffer.</span><br><span class="token keyword">await</span> gpuReadBuffer<span class="token punctuation">.</span><span class="token function">mapAsync</span><span class="token punctuation">(</span>GPUMapMode<span class="token punctuation">.</span><span class="token constant">READ</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><span class="token keyword">const</span> copyArrayBuffer <span class="token operator">=</span> gpuReadBuffer<span class="token punctuation">.</span><span class="token function">getMappedRange</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br>console<span class="token punctuation">.</span><span class="token function">log</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Uint8Array</span><span class="token punctuation">(</span>copyArrayBuffer<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre>
</web-copy-code><p>You can <a href="https://glitch.com/edit/#!/gpu-compute-sample-1" rel="noopener">try out this sample</a>.</p>
<div class="glitch-embed-wrap" style="height: 420px; width: 100%;">
  <iframe
    allow="camera; clipboard-read; clipboard-write; encrypted-media; geolocation; microphone; midi"
    loading="lazy"
    src="https://glitch.com/embed/#!/embed/gpu-compute-sample-1?attributionHidden=true&sidebarCollapsed=true&path=script.js&previewSize=0"
    style="height: 100%; width: 100%; border: 0;"
    title="gpu-compute-sample-1 on Glitch"
  ></iframe>
</div>
<p>In short, here's what you need to remember regarding buffer memory operations:</p>
<ul>
<li>GPU buffers have to be unmapped to be used in device queue submission.</li>
<li>When mapped, GPU buffers can be read and written in JavaScript.</li>
<li>GPU buffers are mapped when <code>mapAsync()</code> and <code>createBuffer()</code> with
<code>mappedAtCreation</code> set to true are called.</li>
</ul>
<h2 id="shader-programming">Shader programming <a class="w-headline-link" href="#shader-programming">#</a></h2>
<p>Programs running on the GPU that only perform computations (and don't draw
triangles) are called compute shaders. They are executed in parallel by hundreds
of GPU cores (which are smaller than CPU cores) that operate together to crunch
data. Their input and output are buffers in WebGPU.</p>
<p>To illustrate the use of compute shaders in WebGPU, we'll play with matrix
multiplication, a common algorithm in machine learning illustrated below.</p>
<figure class="w-figure">
  <img     alt="Matrix multiplication diagram"          decoding="async"     height="369"          loading="lazy"     sizes="(min-width: 800px) 800px, calc(100vw - 48px)"     src="https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/q9PYk219Ykt873iQa0Vc.jpeg?auto=format"     srcset="https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/q9PYk219Ykt873iQa0Vc.jpeg?auto=format&w=200 200w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/q9PYk219Ykt873iQa0Vc.jpeg?auto=format&w=228 228w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/q9PYk219Ykt873iQa0Vc.jpeg?auto=format&w=260 260w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/q9PYk219Ykt873iQa0Vc.jpeg?auto=format&w=296 296w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/q9PYk219Ykt873iQa0Vc.jpeg?auto=format&w=338 338w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/q9PYk219Ykt873iQa0Vc.jpeg?auto=format&w=385 385w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/q9PYk219Ykt873iQa0Vc.jpeg?auto=format&w=439 439w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/q9PYk219Ykt873iQa0Vc.jpeg?auto=format&w=500 500w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/q9PYk219Ykt873iQa0Vc.jpeg?auto=format&w=571 571w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/q9PYk219Ykt873iQa0Vc.jpeg?auto=format&w=650 650w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/q9PYk219Ykt873iQa0Vc.jpeg?auto=format&w=741 741w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/q9PYk219Ykt873iQa0Vc.jpeg?auto=format&w=845 845w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/q9PYk219Ykt873iQa0Vc.jpeg?auto=format&w=964 964w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/q9PYk219Ykt873iQa0Vc.jpeg?auto=format&w=1098 1098w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/q9PYk219Ykt873iQa0Vc.jpeg?auto=format&w=1252 1252w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/q9PYk219Ykt873iQa0Vc.jpeg?auto=format&w=1428 1428w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/q9PYk219Ykt873iQa0Vc.jpeg?auto=format&w=1600 1600w"          width="800"   />
  <figcaption>Matrix multiplication diagram</figcaption>
</figure>
<p>In short, here's what we're going to do:</p>
<ol>
<li>Create three GPU buffers (two for the matrices to multiply and one for the
result matrix)</li>
<li>Describe input and output for the compute shader</li>
<li>Compile the compute shader code</li>
<li>Set up a compute pipeline</li>
<li>Submit in batch the encoded commands to the GPU</li>
<li>Read the result matrix GPU buffer</li>
</ol>
<h3 id="gpu-buffers-creation">GPU Buffers creation <a class="w-headline-link" href="#gpu-buffers-creation">#</a></h3>
<p>For the sake of simplicity, matrices will be represented as a list of floating
point numbers. The first element is the number of rows, the second element the
number of columns, and the rest is the actual numbers of the matrix.</p>
<figure class="w-figure">
  <img     alt="Simple representation of a matrix in JavaScript and its equivalent in mathematical notation"          decoding="async"     height="158"          loading="lazy"     sizes="(min-width: 800px) 800px, calc(100vw - 48px)"     src="https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/IUv15DMl2yDwTGxeJNux.jpeg?auto=format"     srcset="https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/IUv15DMl2yDwTGxeJNux.jpeg?auto=format&w=200 200w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/IUv15DMl2yDwTGxeJNux.jpeg?auto=format&w=228 228w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/IUv15DMl2yDwTGxeJNux.jpeg?auto=format&w=260 260w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/IUv15DMl2yDwTGxeJNux.jpeg?auto=format&w=296 296w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/IUv15DMl2yDwTGxeJNux.jpeg?auto=format&w=338 338w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/IUv15DMl2yDwTGxeJNux.jpeg?auto=format&w=385 385w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/IUv15DMl2yDwTGxeJNux.jpeg?auto=format&w=439 439w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/IUv15DMl2yDwTGxeJNux.jpeg?auto=format&w=500 500w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/IUv15DMl2yDwTGxeJNux.jpeg?auto=format&w=571 571w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/IUv15DMl2yDwTGxeJNux.jpeg?auto=format&w=650 650w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/IUv15DMl2yDwTGxeJNux.jpeg?auto=format&w=741 741w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/IUv15DMl2yDwTGxeJNux.jpeg?auto=format&w=845 845w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/IUv15DMl2yDwTGxeJNux.jpeg?auto=format&w=964 964w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/IUv15DMl2yDwTGxeJNux.jpeg?auto=format&w=1098 1098w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/IUv15DMl2yDwTGxeJNux.jpeg?auto=format&w=1252 1252w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/IUv15DMl2yDwTGxeJNux.jpeg?auto=format&w=1428 1428w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/IUv15DMl2yDwTGxeJNux.jpeg?auto=format&w=1600 1600w"          width="800"   />
  <figcaption>Simple representation of a matrix in JavaScript and its equivalent in mathematical notation</figcaption>
</figure>
<p>The three GPU buffers are storage buffers as we need to store and retrieve data in
the compute shader. This explains why the GPU buffer usage flags include
<code>GPUBufferUsage.STORAGE</code> for all of them. The result matrix usage flag also has
<code>GPUBufferUsage.COPY_SRC</code> because it will be copied to another buffer for
reading once all GPU queue commands have all been executed.</p>
<web-copy-code><pre class="language-js"><code class="language-js"><span class="token keyword">const</span> adapter <span class="token operator">=</span> <span class="token keyword">await</span> navigator<span class="token punctuation">.</span>gpu<span class="token punctuation">.</span><span class="token function">requestAdapter</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>adapter<span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token keyword">return</span><span class="token punctuation">;</span> <span class="token punctuation">}</span><br><span class="token keyword">const</span> device <span class="token operator">=</span> <span class="token keyword">await</span> adapter<span class="token punctuation">.</span><span class="token function">requestDevice</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><br><br><span class="token comment">// First Matrix</span><br><br><span class="token keyword">const</span> firstMatrix <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Float32Array</span><span class="token punctuation">(</span><span class="token punctuation">[</span><br>  <span class="token number">2</span> <span class="token comment">/* rows */</span><span class="token punctuation">,</span> <span class="token number">4</span> <span class="token comment">/* columns */</span><span class="token punctuation">,</span><br>  <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span><br>  <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><br><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><br><span class="token keyword">const</span> gpuBufferFirstMatrix <span class="token operator">=</span> device<span class="token punctuation">.</span><span class="token function">createBuffer</span><span class="token punctuation">(</span><span class="token punctuation">{</span><br>  mappedAtCreation<span class="token operator">:</span> <span class="token boolean">true</span><span class="token punctuation">,</span><br>  size<span class="token operator">:</span> firstMatrix<span class="token punctuation">.</span>byteLength<span class="token punctuation">,</span><br>  usage<span class="token operator">:</span> GPUBufferUsage<span class="token punctuation">.</span><span class="token constant">STORAGE</span><span class="token punctuation">,</span><br><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><span class="token keyword">const</span> arrayBufferFirstMatrix <span class="token operator">=</span> gpuBufferFirstMatrix<span class="token punctuation">.</span><span class="token function">getMappedRange</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><span class="token keyword">new</span> <span class="token class-name">Float32Array</span><span class="token punctuation">(</span>arrayBufferFirstMatrix<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>firstMatrix<span class="token punctuation">)</span><span class="token punctuation">;</span><br>gpuBufferFirstMatrix<span class="token punctuation">.</span><span class="token function">unmap</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><br><br><span class="token comment">// Second Matrix</span><br><br><span class="token keyword">const</span> secondMatrix <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Float32Array</span><span class="token punctuation">(</span><span class="token punctuation">[</span><br>  <span class="token number">4</span> <span class="token comment">/* rows */</span><span class="token punctuation">,</span> <span class="token number">2</span> <span class="token comment">/* columns */</span><span class="token punctuation">,</span><br>  <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span><br>  <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span><br>  <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span><br>  <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><br><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><br><span class="token keyword">const</span> gpuBufferSecondMatrix <span class="token operator">=</span> device<span class="token punctuation">.</span><span class="token function">createBuffer</span><span class="token punctuation">(</span><span class="token punctuation">{</span><br>  mappedAtCreation<span class="token operator">:</span> <span class="token boolean">true</span><span class="token punctuation">,</span><br>  size<span class="token operator">:</span> secondMatrix<span class="token punctuation">.</span>byteLength<span class="token punctuation">,</span><br>  usage<span class="token operator">:</span> GPUBufferUsage<span class="token punctuation">.</span><span class="token constant">STORAGE</span><span class="token punctuation">,</span><br><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><span class="token keyword">const</span> arrayBufferSecondMatrix <span class="token operator">=</span> gpuBufferSecondMatrix<span class="token punctuation">.</span><span class="token function">getMappedRange</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><span class="token keyword">new</span> <span class="token class-name">Float32Array</span><span class="token punctuation">(</span>arrayBufferSecondMatrix<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>secondMatrix<span class="token punctuation">)</span><span class="token punctuation">;</span><br>gpuBufferSecondMatrix<span class="token punctuation">.</span><span class="token function">unmap</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><br><br><span class="token comment">// Result Matrix</span><br><br><span class="token keyword">const</span> resultMatrixBufferSize <span class="token operator">=</span> Float32Array<span class="token punctuation">.</span><span class="token constant">BYTES_PER_ELEMENT</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">+</span> firstMatrix<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> secondMatrix<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><span class="token keyword">const</span> resultMatrixBuffer <span class="token operator">=</span> device<span class="token punctuation">.</span><span class="token function">createBuffer</span><span class="token punctuation">(</span><span class="token punctuation">{</span><br>  size<span class="token operator">:</span> resultMatrixBufferSize<span class="token punctuation">,</span><br>  usage<span class="token operator">:</span> GPUBufferUsage<span class="token punctuation">.</span><span class="token constant">STORAGE</span> <span class="token operator">|</span> GPUBufferUsage<span class="token punctuation">.</span><span class="token constant">COPY_SRC</span><br><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre>
</web-copy-code><h3 id="bind-group-layout-and-bind-group">Bind group layout and bind group <a class="w-headline-link" href="#bind-group-layout-and-bind-group">#</a></h3>
<p>Concepts of bind group layout and bind group are specific to WebGPU. A bind
group layout defines the input/output interface expected by a shader, while a
bind group represents the actual input/output data for a shader.</p>
<p>In the example below, the bind group layout expects two readonly storage buffers at
numbered entry bindings <code>0</code>, <code>1</code>, and a storage buffer at <code>2</code> for the compute shader.
The bind group on the other hand, defined for this bind group layout, associates
GPU buffers to the entries: <code>gpuBufferFirstMatrix</code> to the binding <code>0</code>,
<code>gpuBufferSecondMatrix</code> to the binding <code>1</code>, and <code>resultMatrixBuffer</code> to the
binding <code>2</code>.</p>
<web-copy-code><pre class="language-js"><code class="language-js"><span class="token keyword">const</span> bindGroupLayout <span class="token operator">=</span> device<span class="token punctuation">.</span><span class="token function">createBindGroupLayout</span><span class="token punctuation">(</span><span class="token punctuation">{</span><br>  entries<span class="token operator">:</span> <span class="token punctuation">[</span><br>    <span class="token punctuation">{</span><br>      binding<span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span><br>      visibility<span class="token operator">:</span> GPUShaderStage<span class="token punctuation">.</span><span class="token constant">COMPUTE</span><span class="token punctuation">,</span><br>      buffer<span class="token operator">:</span> <span class="token punctuation">{</span><br>        type<span class="token operator">:</span> <span class="token string">"read-only-storage"</span><br>      <span class="token punctuation">}</span><br>    <span class="token punctuation">}</span><span class="token punctuation">,</span><br>    <span class="token punctuation">{</span><br>      binding<span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">,</span><br>      visibility<span class="token operator">:</span> GPUShaderStage<span class="token punctuation">.</span><span class="token constant">COMPUTE</span><span class="token punctuation">,</span><br>      buffer<span class="token operator">:</span> <span class="token punctuation">{</span><br>        type<span class="token operator">:</span> <span class="token string">"read-only-storage"</span><br>      <span class="token punctuation">}</span><br>    <span class="token punctuation">}</span><span class="token punctuation">,</span><br>    <span class="token punctuation">{</span><br>      binding<span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span><br>      visibility<span class="token operator">:</span> GPUShaderStage<span class="token punctuation">.</span><span class="token constant">COMPUTE</span><span class="token punctuation">,</span><br>      buffer<span class="token operator">:</span> <span class="token punctuation">{</span><br>        type<span class="token operator">:</span> <span class="token string">"storage"</span><br>      <span class="token punctuation">}</span><br>    <span class="token punctuation">}</span><br>  <span class="token punctuation">]</span><br><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><br><span class="token keyword">const</span> bindGroup <span class="token operator">=</span> device<span class="token punctuation">.</span><span class="token function">createBindGroup</span><span class="token punctuation">(</span><span class="token punctuation">{</span><br>  layout<span class="token operator">:</span> bindGroupLayout<span class="token punctuation">,</span><br>  entries<span class="token operator">:</span> <span class="token punctuation">[</span><br>    <span class="token punctuation">{</span><br>      binding<span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span><br>      resource<span class="token operator">:</span> <span class="token punctuation">{</span><br>        buffer<span class="token operator">:</span> gpuBufferFirstMatrix<br>      <span class="token punctuation">}</span><br>    <span class="token punctuation">}</span><span class="token punctuation">,</span><br>    <span class="token punctuation">{</span><br>      binding<span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">,</span><br>      resource<span class="token operator">:</span> <span class="token punctuation">{</span><br>        buffer<span class="token operator">:</span> gpuBufferSecondMatrix<br>      <span class="token punctuation">}</span><br>    <span class="token punctuation">}</span><span class="token punctuation">,</span><br>    <span class="token punctuation">{</span><br>      binding<span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span><br>      resource<span class="token operator">:</span> <span class="token punctuation">{</span><br>        buffer<span class="token operator">:</span> resultMatrixBuffer<br>      <span class="token punctuation">}</span><br>    <span class="token punctuation">}</span><br>  <span class="token punctuation">]</span><br><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre>
</web-copy-code><h3 id="compute-shader-code">Compute shader code <a class="w-headline-link" href="#compute-shader-code">#</a></h3>
<p>The compute shader code for multiplying matrices is written in <a href="https://gpuweb.github.io/gpuweb/wgsl/" rel="noopener">WGSL</a>, the
WebGPU Shader Language, that is trivially translatable to <a href="https://www.khronos.org/spir/" rel="noopener">SPIR-V</a>. Without
going into detail, you should find below the three storage buffers identified
with <code>var&lt;storage&gt;</code>. The program will use <code>firstMatrix</code> and <code>secondMatrix</code> as
inputs and <code>resultMatrix</code> as its output.</p>
<p>Note that each storage buffer has a <code>binding</code> decoration used that corresponds to
the same index defined in bind group layouts and bind groups declared above.</p>
<web-copy-code><pre class="language-js"><code class="language-js"><span class="token keyword">const</span> shaderModule <span class="token operator">=</span> device<span class="token punctuation">.</span><span class="token function">createShaderModule</span><span class="token punctuation">(</span><span class="token punctuation">{</span><br>  code<span class="token operator">:</span> <span class="token template-string"><span class="token template-punctuation string">`</span><span class="token string"><br>    [[block]] struct Matrix {<br>      size : vec2&lt;f32>;<br>      numbers: array&lt;f32>;<br>    };<br><br>    [[group(0), binding(0)]] var&lt;storage, read> firstMatrix : Matrix;<br>    [[group(0), binding(1)]] var&lt;storage, read> secondMatrix : Matrix;<br>    [[group(0), binding(2)]] var&lt;storage, write> resultMatrix : Matrix;<br><br>    [[stage(compute), workgroup_size(8, 8)]]<br>    fn main([[builtin(global_invocation_id)]] global_id : vec3&lt;u32>) {<br>      // Guard against out-of-bounds work group sizes<br>      if (global_id.x >= u32(firstMatrix.size.x) || global_id.y >= u32(secondMatrix.size.y)) {<br>        return;<br>      }<br><br>      resultMatrix.size = vec2&lt;f32>(firstMatrix.size.x, secondMatrix.size.y);<br><br>      let resultCell = vec2&lt;u32>(global_id.x, global_id.y);<br>      var result = 0.0;<br>      for (var i = 0u; i &lt; u32(firstMatrix.size.y); i = i + 1u) {<br>        let a = i + resultCell.x * u32(firstMatrix.size.y);<br>        let b = resultCell.y + i * u32(secondMatrix.size.y);<br>        result = result + firstMatrix.numbers[a] * secondMatrix.numbers[b];<br>      }<br><br>      let index = resultCell.y + resultCell.x * u32(secondMatrix.size.y);<br>      resultMatrix.numbers[index] = result;<br>    }<br>  </span><span class="token template-punctuation string">`</span></span><br><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre>
</web-copy-code><h3 id="pipeline-setup">Pipeline setup <a class="w-headline-link" href="#pipeline-setup">#</a></h3>
<p>The compute pipeline is the object that actually describes the compute operation
we're going to perform. Create it by calling <code>device.createComputePipeline()</code>.
It takes two arguments: the bind group layout we created earlier, and a compute
stage defining the entry point of our compute shader (the <code>main</code> WGSL function)
and the actual compute shader module created with <code>device.createShaderModule()</code>.</p>
<web-copy-code><pre class="language-js"><code class="language-js"><span class="token keyword">const</span> computePipeline <span class="token operator">=</span> device<span class="token punctuation">.</span><span class="token function">createComputePipeline</span><span class="token punctuation">(</span><span class="token punctuation">{</span><br>  layout<span class="token operator">:</span> device<span class="token punctuation">.</span><span class="token function">createPipelineLayout</span><span class="token punctuation">(</span><span class="token punctuation">{</span><br>    bindGroupLayouts<span class="token operator">:</span> <span class="token punctuation">[</span>bindGroupLayout<span class="token punctuation">]</span><br>  <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>  compute<span class="token operator">:</span> <span class="token punctuation">{</span><br>    module<span class="token operator">:</span> shaderModule<span class="token punctuation">,</span><br>    entryPoint<span class="token operator">:</span> <span class="token string">"main"</span><br>  <span class="token punctuation">}</span><br><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre>
</web-copy-code><h3 id="commands-submission">Commands submission <a class="w-headline-link" href="#commands-submission">#</a></h3>
<p>After instantiating a bind group with our three GPU buffers and a compute
pipeline with a bind group layout, it is time to use them.</p>
<p>Let's start a programmable compute pass encoder with
<code>commandEncoder.beginComputePass()</code>. We'll use this to encode GPU commands
that will perform the matrix multiplication. Set its pipeline with
<code>passEncoder.setPipeline(computePipeline)</code> and its bind group at index 0 with
<code>passEncoder.setBindGroup(0, bindGroup)</code>. The index 0 corresponds to the
<code>group(0)</code> decoration in the WGSL code.</p>
<p>Now, let's talk about how this compute shader is going to run on the GPU. Our
goal is to execute this program in parallel for each cell of the result matrix,
step by step. For a result matrix of size 2 by 4 for instance, we'd call
<code>passEncoder.dispatch(2, 4)</code> to encode the command of execution. The first
argument &quot;x&quot; is the first dimension, the second one &quot;y&quot; is the second dimension,
and the latest one &quot;z&quot; is the third dimension that defaults to 1 as we don't
need it here. In the GPU compute world, encoding a command to execute a kernel
function on a set of data is called dispatching.</p>
<figure class="w-figure">
  <img     alt="Execution in parallel for each result matrix cell"          decoding="async"     height="530"          loading="lazy"     sizes="(min-width: 800px) 800px, calc(100vw - 48px)"     src="https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format"     srcset="https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format&w=200 200w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format&w=228 228w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format&w=260 260w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format&w=296 296w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format&w=338 338w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format&w=385 385w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format&w=439 439w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format&w=500 500w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format&w=571 571w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format&w=650 650w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format&w=741 741w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format&w=845 845w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format&w=964 964w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format&w=1098 1098w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format&w=1252 1252w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format&w=1428 1428w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/AwjccGqafT2OOWqLGdDX.jpeg?auto=format&w=1600 1600w"          width="800"   />
  <figcaption>Execution in parallel for each result matrix cell</figcaption>
</figure>
<p>The size of the workgroup grid for our compute shader is <code>(8, 8)</code> in our WGSL
code. Because of that, &quot;x&quot; and &quot;y&quot; that are respectively the number of rows of
the first matrix and the number of columns of the second matrix will be divided
by 8. With that, we can now dispatch a compute call with
<code>passEncoder.dispatch(firstMatrix[0] / 8, secondMatrix[1] / 8)</code>. The number of
workgroup grids to run are the <code>dispatch()</code> arguments.</p>
<p>As seen in the drawing above, each shader will have access to a unique
<code>builtin(global_invocation_id)</code> object that will be used to know which result
matrix cell to compute.</p>
<web-copy-code><pre class="language-js"><code class="language-js"><span class="token keyword">const</span> commandEncoder <span class="token operator">=</span> device<span class="token punctuation">.</span><span class="token function">createCommandEncoder</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><br><span class="token keyword">const</span> passEncoder <span class="token operator">=</span> commandEncoder<span class="token punctuation">.</span><span class="token function">beginComputePass</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br>passEncoder<span class="token punctuation">.</span><span class="token function">setPipeline</span><span class="token punctuation">(</span>computePipeline<span class="token punctuation">)</span><span class="token punctuation">;</span><br>passEncoder<span class="token punctuation">.</span><span class="token function">setBindGroup</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> bindGroup<span class="token punctuation">)</span><span class="token punctuation">;</span><br><span class="token keyword">const</span> x <span class="token operator">=</span> Math<span class="token punctuation">.</span><span class="token function">ceil</span><span class="token punctuation">(</span>firstMatrix<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">/</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// X dimension of the grid of workgroups to dispatch.</span><br><span class="token keyword">const</span> y <span class="token operator">=</span> Math<span class="token punctuation">.</span><span class="token function">ceil</span><span class="token punctuation">(</span>secondMatrix<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">/</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// Y dimension of the grid of workgroups to dispatch.</span><br>passEncoder<span class="token punctuation">.</span><span class="token function">dispatch</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">;</span><br>passEncoder<span class="token punctuation">.</span><span class="token function">endPass</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre>
</web-copy-code><p>To end the compute pass encoder, call <code>passEncoder.endPass()</code>. Then, create a
GPU buffer to use as a destination to copy the result matrix buffer with
<code>copyBufferToBuffer</code>. Finally, finish encoding commands with
<code>copyEncoder.finish()</code> and submit those to the GPU device queue by calling
<code>device.queue.submit()</code> with the GPU commands.</p>
<web-copy-code><pre class="language-js"><code class="language-js"><span class="token comment">// Get a GPU buffer for reading in an unmapped state.</span><br><span class="token keyword">const</span> gpuReadBuffer <span class="token operator">=</span> device<span class="token punctuation">.</span><span class="token function">createBuffer</span><span class="token punctuation">(</span><span class="token punctuation">{</span><br>  size<span class="token operator">:</span> resultMatrixBufferSize<span class="token punctuation">,</span><br>  usage<span class="token operator">:</span> GPUBufferUsage<span class="token punctuation">.</span><span class="token constant">COPY_DST</span> <span class="token operator">|</span> GPUBufferUsage<span class="token punctuation">.</span><span class="token constant">MAP_READ</span><br><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><br><span class="token comment">// Encode commands for copying buffer to buffer.</span><br>commandEncoder<span class="token punctuation">.</span><span class="token function">copyBufferToBuffer</span><span class="token punctuation">(</span><br>  resultMatrixBuffer <span class="token comment">/* source buffer */</span><span class="token punctuation">,</span><br>  <span class="token number">0</span> <span class="token comment">/* source offset */</span><span class="token punctuation">,</span><br>  gpuReadBuffer <span class="token comment">/* destination buffer */</span><span class="token punctuation">,</span><br>  <span class="token number">0</span> <span class="token comment">/* destination offset */</span><span class="token punctuation">,</span><br>  resultMatrixBufferSize <span class="token comment">/* size */</span><br><span class="token punctuation">)</span><span class="token punctuation">;</span><br><br><span class="token comment">// Submit GPU commands.</span><br><span class="token keyword">const</span> gpuCommands <span class="token operator">=</span> commandEncoder<span class="token punctuation">.</span><span class="token function">finish</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br>device<span class="token punctuation">.</span>queue<span class="token punctuation">.</span><span class="token function">submit</span><span class="token punctuation">(</span><span class="token punctuation">[</span>gpuCommands<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre>
</web-copy-code><h3 id="read-result-matrix">Read result matrix <a class="w-headline-link" href="#read-result-matrix">#</a></h3>
<p>Reading the result matrix is as easy as calling <code>gpuReadBuffer.mapAsync()</code> with
<code>GPUMapMode.READ</code> and waiting for the returning promise to resolve which indicates
the GPU buffer is now mapped. At this point, it is possible to get the mapped
range with <code>gpuReadBuffer.getMappedRange()</code>.</p>
<figure class="w-figure">
<img     alt="Matrix multiplication result"          decoding="async"     height="196"          loading="lazy"     sizes="(min-width: 800px) 800px, calc(100vw - 48px)"     src="https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/L4fXrCemYcZ5FwAcmRHH.jpeg?auto=format"     srcset="https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/L4fXrCemYcZ5FwAcmRHH.jpeg?auto=format&w=200 200w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/L4fXrCemYcZ5FwAcmRHH.jpeg?auto=format&w=228 228w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/L4fXrCemYcZ5FwAcmRHH.jpeg?auto=format&w=260 260w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/L4fXrCemYcZ5FwAcmRHH.jpeg?auto=format&w=296 296w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/L4fXrCemYcZ5FwAcmRHH.jpeg?auto=format&w=338 338w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/L4fXrCemYcZ5FwAcmRHH.jpeg?auto=format&w=385 385w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/L4fXrCemYcZ5FwAcmRHH.jpeg?auto=format&w=439 439w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/L4fXrCemYcZ5FwAcmRHH.jpeg?auto=format&w=500 500w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/L4fXrCemYcZ5FwAcmRHH.jpeg?auto=format&w=571 571w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/L4fXrCemYcZ5FwAcmRHH.jpeg?auto=format&w=650 650w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/L4fXrCemYcZ5FwAcmRHH.jpeg?auto=format&w=741 741w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/L4fXrCemYcZ5FwAcmRHH.jpeg?auto=format&w=845 845w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/L4fXrCemYcZ5FwAcmRHH.jpeg?auto=format&w=964 964w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/L4fXrCemYcZ5FwAcmRHH.jpeg?auto=format&w=1098 1098w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/L4fXrCemYcZ5FwAcmRHH.jpeg?auto=format&w=1252 1252w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/L4fXrCemYcZ5FwAcmRHH.jpeg?auto=format&w=1428 1428w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/L4fXrCemYcZ5FwAcmRHH.jpeg?auto=format&w=1600 1600w"          width="800"   />  <figcaption>Matrix multiplication result</figcaption>
</figure>
<p>In our code, the result logged in DevTools JavaScript console is &quot;2, 2, 50, 60,
114, 140&quot;.</p>
<web-copy-code><pre class="language-js"><code class="language-js"><span class="token comment">// Read buffer.</span><br><span class="token keyword">await</span> gpuReadBuffer<span class="token punctuation">.</span><span class="token function">mapAsync</span><span class="token punctuation">(</span>GPUMapMode<span class="token punctuation">.</span><span class="token constant">READ</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br><span class="token keyword">const</span> arrayBuffer <span class="token operator">=</span> gpuReadBuffer<span class="token punctuation">.</span><span class="token function">getMappedRange</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><br>console<span class="token punctuation">.</span><span class="token function">log</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Float32Array</span><span class="token punctuation">(</span>arrayBuffer<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre>
</web-copy-code><p>Congratulations! You made it. You can <a href="https://glitch.com/edit/#!/gpu-compute-sample-2" rel="noopener">play with the sample</a>.</p>
<div class="glitch-embed-wrap" style="height: 420px; width: 100%;">
  <iframe
    allow="camera; clipboard-read; clipboard-write; encrypted-media; geolocation; microphone; midi"
    loading="lazy"
    src="https://glitch.com/embed/#!/embed/gpu-compute-sample-2?attributionHidden=true&sidebarCollapsed=true&path=script.js&previewSize=0"
    style="height: 100%; width: 100%; border: 0;"
    title="gpu-compute-sample-2 on Glitch"
  ></iframe>
</div>
<h2 id="one-last-trick">One last trick <a class="w-headline-link" href="#one-last-trick">#</a></h2>
<p>One way of making your code easier to read is to use the handy
<code>getBindGroupLayout</code> method of the compute pipeline to <a href="https://github.com/gpuweb/gpuweb/issues/446" rel="noopener">infer the bind group
layout from the shader module</a>. This trick removes the need from creating a
custom bind group layout and specifying a pipeline layout in your compute
pipeline as you can see below.</p>
<p>An illustration of <code>getBindGroupLayout</code> for the previous sample is <a href="https://glitch.com/edit/#!/gpu-compute-sample-3" rel="noopener">available</a>.</p>
<div class="glitch-embed-wrap" style="height: 420px; width: 100%;">
  <iframe
    allow="camera; clipboard-read; clipboard-write; encrypted-media; geolocation; microphone; midi"
    loading="lazy"
    src="https://glitch.com/embed/#!/embed/gpu-compute-sample-3?attributionHidden=true&sidebarCollapsed=true&path=script.js&previewSize=0"
    style="height: 100%; width: 100%; border: 0;"
    title="gpu-compute-sample-3 on Glitch"
  ></iframe>
</div>
<web-copy-code><pre class="language-js"><code class="language-js"><span class="highlight-line"> <span class="token keyword">const</span> computePipeline <span class="token operator">=</span> device<span class="token punctuation">.</span><span class="token function">createComputePipeline</span><span class="token punctuation">(</span><span class="token punctuation">{</span></span><br><del class="highlight-line highlight-line-remove"><span class="token operator">-</span>  layout<span class="token operator">:</span> device<span class="token punctuation">.</span><span class="token function">createPipelineLayout</span><span class="token punctuation">(</span><span class="token punctuation">{</span></del><br><del class="highlight-line highlight-line-remove"><span class="token operator">-</span>    bindGroupLayouts<span class="token operator">:</span> <span class="token punctuation">[</span>bindGroupLayout<span class="token punctuation">]</span></del><br><del class="highlight-line highlight-line-remove"><span class="token operator">-</span>  <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span></del><br><span class="highlight-line">   compute<span class="token operator">:</span> <span class="token punctuation">{</span></span></code></pre>
</web-copy-code><web-copy-code><pre class="language-js"><code class="language-js"><del class="highlight-line highlight-line-remove"><span class="token operator">-</span><span class="token comment">// Bind group layout and bind group</span></del><br><del class="highlight-line highlight-line-remove"><span class="token operator">-</span> <span class="token keyword">const</span> bindGroupLayout <span class="token operator">=</span> device<span class="token punctuation">.</span><span class="token function">createBindGroupLayout</span><span class="token punctuation">(</span><span class="token punctuation">{</span></del><br><del class="highlight-line highlight-line-remove"><span class="token operator">-</span>   entries<span class="token operator">:</span> <span class="token punctuation">[</span></del><br><del class="highlight-line highlight-line-remove"><span class="token operator">-</span>     <span class="token punctuation">{</span></del><br><del class="highlight-line highlight-line-remove"><span class="token operator">-</span>       binding<span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span></del><br><del class="highlight-line highlight-line-remove"><span class="token operator">-</span>       visibility<span class="token operator">:</span> GPUShaderStage<span class="token punctuation">.</span><span class="token constant">COMPUTE</span><span class="token punctuation">,</span></del><br><del class="highlight-line highlight-line-remove"><span class="token operator">-</span>       buffer<span class="token operator">:</span> <span class="token punctuation">{</span></del><br><del class="highlight-line highlight-line-remove"><span class="token operator">-</span>         type<span class="token operator">:</span> <span class="token string">"read-only-storage"</span></del><br><del class="highlight-line highlight-line-remove"><span class="token operator">-</span>       <span class="token punctuation">}</span></del><br><del class="highlight-line highlight-line-remove"><span class="token operator">-</span>     <span class="token punctuation">}</span><span class="token punctuation">,</span></del><br><del class="highlight-line highlight-line-remove"><span class="token operator">-</span>     <span class="token punctuation">{</span></del><br><del class="highlight-line highlight-line-remove"><span class="token operator">-</span>       binding<span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">,</span></del><br><del class="highlight-line highlight-line-remove"><span class="token operator">-</span>       visibility<span class="token operator">:</span> GPUShaderStage<span class="token punctuation">.</span><span class="token constant">COMPUTE</span><span class="token punctuation">,</span></del><br><del class="highlight-line highlight-line-remove"><span class="token operator">-</span>       buffer<span class="token operator">:</span> <span class="token punctuation">{</span></del><br><del class="highlight-line highlight-line-remove"><span class="token operator">-</span>         type<span class="token operator">:</span> <span class="token string">"read-only-storage"</span></del><br><del class="highlight-line highlight-line-remove"><span class="token operator">-</span>       <span class="token punctuation">}</span></del><br><del class="highlight-line highlight-line-remove"><span class="token operator">-</span>     <span class="token punctuation">}</span><span class="token punctuation">,</span></del><br><del class="highlight-line highlight-line-remove"><span class="token operator">-</span>     <span class="token punctuation">{</span></del><br><del class="highlight-line highlight-line-remove"><span class="token operator">-</span>       binding<span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span></del><br><del class="highlight-line highlight-line-remove"><span class="token operator">-</span>       visibility<span class="token operator">:</span> GPUShaderStage<span class="token punctuation">.</span><span class="token constant">COMPUTE</span><span class="token punctuation">,</span></del><br><del class="highlight-line highlight-line-remove"><span class="token operator">-</span>       buffer<span class="token operator">:</span> <span class="token punctuation">{</span></del><br><del class="highlight-line highlight-line-remove"><span class="token operator">-</span>         type<span class="token operator">:</span> <span class="token string">"storage"</span></del><br><del class="highlight-line highlight-line-remove"><span class="token operator">-</span>       <span class="token punctuation">}</span></del><br><del class="highlight-line highlight-line-remove"><span class="token operator">-</span>     <span class="token punctuation">}</span></del><br><del class="highlight-line highlight-line-remove"><span class="token operator">-</span>   <span class="token punctuation">]</span></del><br><del class="highlight-line highlight-line-remove"><span class="token operator">-</span> <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span></del><br><ins class="highlight-line highlight-line-add"><span class="token operator">+</span><span class="token comment">// Bind group</span></ins><br><span class="highlight-line">  <span class="token keyword">const</span> bindGroup <span class="token operator">=</span> device<span class="token punctuation">.</span><span class="token function">createBindGroup</span><span class="token punctuation">(</span><span class="token punctuation">{</span></span><br><del class="highlight-line highlight-line-remove"><span class="token operator">-</span>  layout<span class="token operator">:</span> bindGroupLayout<span class="token punctuation">,</span></del><br><ins class="highlight-line highlight-line-add"><span class="token operator">+</span>  layout<span class="token operator">:</span> computePipeline<span class="token punctuation">.</span><span class="token function">getBindGroupLayout</span><span class="token punctuation">(</span><span class="token number">0</span> <span class="token comment">/* index */</span><span class="token punctuation">)</span><span class="token punctuation">,</span></ins><br><span class="highlight-line">   entries<span class="token operator">:</span> <span class="token punctuation">[</span></span></code></pre>
</web-copy-code><h2 id="performance-findings">Performance findings <a class="w-headline-link" href="#performance-findings">#</a></h2>
<p>So how does running matrix multiplication on a GPU compare to running it on a
CPU? To find out, I wrote the program just described for a CPU. And as you can
see in the graph below, using the full power of GPU seems like an obvious choice
when the size of the matrices is greater than 256 by 256.</p>
<figure>
  <img     alt="GPU vs CPU benchmark"          decoding="async"     height="495"          loading="lazy"     sizes="(min-width: 800px) 800px, calc(100vw - 48px)"     src="https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/0sDoKqkuGd1nxUGNf1GI.jpeg?auto=format"     srcset="https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/0sDoKqkuGd1nxUGNf1GI.jpeg?auto=format&w=200 200w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/0sDoKqkuGd1nxUGNf1GI.jpeg?auto=format&w=228 228w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/0sDoKqkuGd1nxUGNf1GI.jpeg?auto=format&w=260 260w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/0sDoKqkuGd1nxUGNf1GI.jpeg?auto=format&w=296 296w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/0sDoKqkuGd1nxUGNf1GI.jpeg?auto=format&w=338 338w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/0sDoKqkuGd1nxUGNf1GI.jpeg?auto=format&w=385 385w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/0sDoKqkuGd1nxUGNf1GI.jpeg?auto=format&w=439 439w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/0sDoKqkuGd1nxUGNf1GI.jpeg?auto=format&w=500 500w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/0sDoKqkuGd1nxUGNf1GI.jpeg?auto=format&w=571 571w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/0sDoKqkuGd1nxUGNf1GI.jpeg?auto=format&w=650 650w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/0sDoKqkuGd1nxUGNf1GI.jpeg?auto=format&w=741 741w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/0sDoKqkuGd1nxUGNf1GI.jpeg?auto=format&w=845 845w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/0sDoKqkuGd1nxUGNf1GI.jpeg?auto=format&w=964 964w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/0sDoKqkuGd1nxUGNf1GI.jpeg?auto=format&w=1098 1098w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/0sDoKqkuGd1nxUGNf1GI.jpeg?auto=format&w=1252 1252w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/0sDoKqkuGd1nxUGNf1GI.jpeg?auto=format&w=1428 1428w,     https://web-dev.imgix.net/image/vvhSqZboQoZZN9wBvoXq72wzGAf1/0sDoKqkuGd1nxUGNf1GI.jpeg?auto=format&w=1600 1600w"          width="800"   />
  <figcaption>GPU vs CPU benchmark</figcaption>
</figure>
<p>This article was just the beginning of my journey <a href="/gpu/">exploring WebGPU</a>. Expect more
articles soon featuring more deep dives in GPU Compute and on how rendering
(canvas, texture, sampler) works in WebGPU.</p>


      
        <div class="w-aside w-aside--note">Have a question about using this feature? You can get help by <a href="https://stackoverflow.com/questions/ask?tags=webgpu">asking a question on Stack Overflow</a>, or <a href="https://stackoverflow.com/search?q=%5Bwebgpu%5D+is%3Aquestion">browsing a list of questions</a> asked by other developers.</div>
      

      <div class="cluster gutter-base flow-space-size-2" role="list" aria-label="tags">
        
          
        
          
        
          
            
            <a class="pill" href="/tags/capabilities/">Capabilities</a>
          
        
          
            
            <a class="pill" href="/tags/games/">Games</a>
          
        
      </div>

      <div class="text-size-0 color-mid-text">
        <span>
          
          Last updated: <time>Oct 18, 2021</time>
          
        </span>
        —
        <a
          href="https://github.com/GoogleChrome/web.dev/blob/main/src/site/content/en/blog/gpu-compute/index.md"
        >
          Improve article
        </a>
      </div>

      

      
        
        
      

      
        <div class="flow-space-size-2">
          <a href="/blog" class="button" data-type="secondary">
            <svg xmlns="http://www.w3.org/2000/svg" height="24" width="24" viewBox="0 0 24 24"><path d="M0 0h24v24H0z" fill="none"/><path d="M20 11H7.83l5.59-5.59L12 4l-8 8 8 8 1.41-1.41L7.83 13H20v-2z"/></svg>

            <span>Return to all articles</span>
          </a>
        </div>
      
      <div class="docked-actions flow flow-space-base">    
        <div>
          <share-action class="gc-analytics-event fab"
            authors="François Beaufort"
            data-category="web.dev"
            data-label="share"
            data-action="click"
            data-type="primary"
            data-icon="share"
            tabindex="0"
            role="button"
          >
            <svg xmlns="http://www.w3.org/2000/svg" height="24" width="24" viewBox="0 0 24 24"><path d="M0 0h24v24H0V0z" fill="none"/><path d="M18 16.1c-.8 0-1.4.3-2 .8l-7.1-4.2c.1-.2.1-.5.1-.7s0-.5-.1-.7L16 7.2c.5.5 1.2.8 2 .8 1.7 0 3-1.3 3-3s-1.3-3-3-3-3 1.3-3 3c0 .2 0 .5.1.7L8 9.8C7.5 9.3 6.8 9 6 9c-1.7 0-3 1.3-3 3s1.3 3 3 3c.8 0 1.5-.3 2-.8l7.1 4.2c-.1.2-.1.4-.1.6 0 1.6 1.3 2.9 2.9 2.9s2.9-1.3 2.9-2.9-1.2-2.9-2.8-2.9z" fill="currentColor"/></svg>
 
            <span class="fab__label">Share</span>
          </share-action>
        </div>
        
      </div>
    </article>
  </div>
</div>


</main>
<footer class="site-footer" role="contentinfo">
  <nav class="site-footer__primary-nav auto-grid" aria-label="footer navigation">
    <div>
      <h3 class="text-size-2 color-mid-text">Contribute</h3>
      <ul class="w-footer__linkbox-list" role="list">
        <li>
          <a href="https://github.com/GoogleChrome/web.dev/issues/new?assignees=&labels=bug&template=bug_report.md&title="
            data-category="Site-Wide Custom Events" data-label="Footer Link (index 1)">
            File a bug
          </a>
        </li>
        <li>
          <a href="https://github.com/googlechrome/web.dev"
            data-category="Site-Wide Custom Events" data-label="Footer Link (index 2)">
            View source
          </a>
        </li>
      </ul>
    </div>
    <div>
      <h3 class="text-size-2 color-mid-text">Related content</h3>
      <ul class="w-footer__linkbox-list" role="list">
          <li>
          <a href="https://developer.chrome.com/"
            data-category="Site-Wide Custom Events" data-label="Footer Link (index 1)">
            developer.chrome.com
          </a>
        </li>
        <li>
          <a href="https://blog.chromium.org/"
            data-category="Site-Wide Custom Events" data-label="Footer Link (index 1)">
            Chrome updates
          </a>
        </li>
        <li>
          <a href="https://developers.google.com/web/fundamentals"
            data-category="Site-Wide Custom Events" data-label="Footer Link (index 2)">
            Web Fundamentals
          </a>
        </li>
        <li>
          <a href="/tags/case-study/"
            data-category="Site-Wide Custom Events" data-label="Footer Link (index 3)">
            Case studies
          </a>
        </li>
        <li>
          <a href="/podcasts/"
            data-category="Podcasts" data-label="Footer Link (index 5)">
            Podcasts
          </a>
        </li>
        <li>
          <a href="/shows/"
            data-category="Shows" data-label="Footer Link (index 6)">
            Shows
          </a>
        </li>
      </ul>
    </div>
    <div>
      <h3 class="text-size-2 color-mid-text">Connect</h3>
      <ul class="w-footer__linkbox-list" role="list">
        <li>
          <a href="https://www.twitter.com/ChromiumDev"
            data-category="Site-Wide Custom Events" data-label="Footer Link (index 1)">
            Twitter
          </a>
        </li>
        <li>
          <a href="https://www.youtube.com/user/ChromeDevelopers"
            data-category="Site-Wide Custom Events" data-label="Footer Link (index 2)">
            YouTube
          </a>
        </li>
      </ul>
    </div>
  </nav>
  <nav class="site-footer__brand-nav repel" aria-label="Google developers">
    <ul class="cluster" role="list">
      <li>
        <a href="https://developers.google.com/" data-category="Site-Wide Custom Events" data-label="Footer Google Developers Link">
          <img loading="lazy" width="185" height="33" class="w-footer__utility-logo" src="/images/lockup-color.png"
            alt="Google Developers" />
        </a>
      </li>
      <li>
        <a href="https://developer.chrome.com/"
          data-category="Site-Wide Custom Events" data-label="Footer Chrome Link">
          Chrome
        </a>
      </li>
      <li>
        <a href="https://firebase.google.com/" data-category="Site-Wide Custom Events"
          data-label="Footer Firebase Link">
          Firebase
        </a>
      </li>
      <li>
        <a href="https://cloud.google.com/" data-category="Site-Wide Custom Events"
          data-label="Footer Google Cloud Platform Link">
          Google Cloud Platform
        </a>
      </li>
      <li>
        <a href="https://developers.google.com/products"
          data-category="Site-Wide Custom Events" data-label="Footer All products Link">
          All products
        </a>
      </li>
    </ul>
    <web-language-select current="en"></web-language-select>
  </nav>
  <nav class="site-footer__misc-links" aria-label="terms and policies">
    <ul class="cluster" role="list">
      <li>
        <a href="https://policies.google.com/" data-category="Site-Wide Custom Events"
          data-label="Footer Terms and Privacy link">
          Terms &amp; Privacy
        </a>
      </li>
      <li>
        <a href="/community-guidelines/" data-category="Site-Wide Custom Events"
          data-label="Footer Community Guidelines link">
          Community Guidelines
        </a>
      </li>
    </ul>
  </nav>
  <p class="gap-top-size-2 text-size-0">
    Except as otherwise noted, the content of this page is licensed
    under the
    <a href="https://creativecommons.org/licenses/by/4.0/">
    Creative Commons Attribution 4.0 License</a>,
    and code samples are licensed under the
    <a href="https://www.apache.org/licenses/LICENSE-2.0">
    Apache 2.0 License</a>. For details, see the
    <a href="https://developers.google.com/terms/site-policies">
    Google Developers Site Policies</a>.
  </p>
</footer>


  </body>
</html>
